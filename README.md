# 小红书商品采集器

一个功能强大的小红书商品数据采集和分析工具，支持多种链接格式，提供完整的数据分析功能。

## 🚀 主要功能

### 1. 数据采集功能
- **多格式链接支持**：
  - 标准商品链接：`https://www.xiaohongshu.com/goods-detail/xxx`
  - 分享链接：包含😆表情符号的完整分享文本
  - 短链接：`http://xhslink.com/xxx`
- **批量处理**：支持同时处理多个商品链接
- **自动去重**：智能识别并去除重复链接
- **图片下载**：可选择保存商品图片到本地
- **实时进度**：显示采集进度和状态

### 2. 数据分析功能
- **商品分析**：
  - 销量趋势分析
  - 日均销量计算
  - 采集次数统计
  - 数据排序和筛选
- **店铺分析**：
  - 店铺销量变化分析
  - 日均出单量计算
  - 店铺数据对比

### 3. 数据管理功能
- **数据库存储**：使用SQLite数据库存储所有数据
- **Excel导入**：支持批量导入Excel文件数据
- **数据导出**：将分析结果导出为Excel文件
- **数据清理**：支持清空数据库重新开始

## 📋 支持的链接格式

### 1. 标准商品链接
```
https://www.xiaohongshu.com/goods-detail/5fvEArEuMPs
```

### 2. 分享链接（新增支持）
```
【小红书】冀教版8上英语讲义测试 😆 5fvEArEuMPs 😆 http://xhslink.com/m/8sRGr0QfpQO 点击链接或者复制本条信息打开【小红书app】查看 MF8056
```
**注意**: 分享链接会提取其中的短链接部分直接使用

### 3. 短链接（直接使用）
```
http://xhslink.com/m/8sRGr0QfpQO
```

## 🛠️ 使用方法

### 1. 启动程序
```bash
python spider.py
```

### 2. 数据采集
1. 在"商品采集"标签页中，将商品链接粘贴到文本框中
2. 每行一个链接，支持混合格式
3. 可选择是否保存商品图片
4. 点击"开始采集"按钮
5. 查看实时日志了解采集进度

### 3. 数据分析
1. 切换到"数据分析"标签页
2. 选择"商品数据分析"或"店铺数据分析"
3. 点击"分析商品数据"或"分析店铺数据"按钮
4. 查看分析结果，支持列排序
5. 可导出分析结果到Excel文件

### 4. 数据导入
1. 点击"导入数据(目录)"或"导入数据(文件)"按钮
2. 选择包含Excel文件的文件夹或单个Excel文件
3. 程序会自动解析并导入数据到数据库

### 5. 测试链接解析
1. 点击"测试链接解析"按钮
2. 程序会测试各种链接格式的解析功能
3. 在日志中查看解析结果

## 📊 数据库结构

### goods表（商品信息）
- `product_id`: 商品ID（主键）
- `title`: 商品标题
- `seller_name`: 店铺名称
- `price`: 商品价格
- `collect_time`: 采集时间
- `count`: 采集次数

### account表（店铺信息）
- `seller_name`: 店铺名称（主键）
- `account_url`: 店铺链接
- `total_sales`: 总销量
- `collect_time`: 采集时间

### collect_data表（商品采集记录）
- `id`: 自增ID（主键）
- `product_id`: 商品ID
- `sales`: 销量
- `collect_time`: 采集时间

### collect_account_data表（店铺采集记录）
- `id`: 自增ID（主键）
- `seller_name`: 店铺名称
- `total_sales`: 总销量
- `collect_time`: 采集时间

## 🔧 技术特点

- **多线程处理**：后台处理避免界面阻塞
- **智能链接解析**：自动识别和转换不同格式的链接
- **简化处理流程**：短链接直接使用，无需复杂转换
- **错误处理**：完善的异常处理机制
- **用户友好**：直观的图形界面和详细的操作提示
- **数据完整性**：支持数据去重和格式标准化

## 📁 文件结构

```
项目根目录/
├── spider.py          # 主程序文件
├── README.md          # 说明文档
├── test_url_fix.py    # URL清理功能测试脚本
├── data/              # 数据存储目录
│   ├── xiaohongshu.db # SQLite数据库
│   └── images/        # 图片存储目录
└── code/              # 其他代码文件
```

## ⚠️ 注意事项

1. **浏览器要求**：需要安装Chrome浏览器
2. **网络连接**：需要稳定的网络连接访问小红书
3. **数据备份**：建议定期备份数据库文件
4. **使用频率**：避免过于频繁的访问，以免被限制

## 🆕 最新更新

### v2.1 错误修复 (2024-12-19)
- ✅ **修复URL处理错误**：解决了Selenium WebDriver的"invalid argument"错误
- ✅ **改进URL清理逻辑**：更好地处理小红书分享链接格式
- ✅ **增强错误处理**：添加URL格式验证和异常捕获
- ✅ **新增测试脚本**：`test_url_fix.py`用于验证URL清理功能

### v2.0 新增功能
- ✅ 支持小红书分享链接格式（包含😆表情符号）
- ✅ 支持短链接直接使用
- ✅ 新增链接解析测试功能
- ✅ 改进用户界面，添加操作说明
- ✅ 优化错误处理和日志输出

## 🐛 问题修复

### 已修复的问题
1. **URL处理错误**：之前程序在处理小红书分享链接时会出现"invalid argument"错误
   - **原因**：传递给Selenium WebDriver的URL包含了完整的分享文本，而不是清理后的URL
   - **解决方案**：改进了URL清理函数，确保只传递有效的HTTP/HTTPS链接给WebDriver
   - **测试**：使用`test_url_fix.py`脚本验证修复效果

## 📞 技术支持

如有问题或建议，请查看程序日志获取详细信息，或联系开发者。

---

**免责声明**：本工具仅用于学习和研究目的，请遵守相关网站的使用条款和法律法规。 